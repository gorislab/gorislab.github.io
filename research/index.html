<!doctype html>
<html class="no-js" lang="en" dir="ltr">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="x-ua-compatible" content="ie=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title> Gorislab - Research Projects </title>
		<link rel="stylesheet" href="/css/foundation.css" type="text/css" media="screen">
		<link rel="stylesheet" href="/css/styles.css" type="text/css" media="screen">
	</head>

	<body>
		<div class="off-canvas-wrapper"> <!-- Definition of global off canvas wrapper -->
				<div class="off-canvas-wrapper-inner" data-off-canvas-wrapper>	<!-- Definition of inner off canvas wrapper -->
				
				<!-- Menu -->
				<div class="off-canvas position-left" id="mobile-menu" data-off-canvas>
        			<ul>
						
						
          				<li><a class="nav-item" href="/research">Research</a></li>
					
					<li><a class="nav-item" href="/publications">Publications</a></li>
					
					<li><a class="nav-item" href="/labmembers">Members</a></li>
					
					<li><a class="nav-item" href="/collabs">Collaborators</a></li>
						
          				<li><a class="nav-item" href="/resources">Resources</a></li>
						
          				<li><a class="nav-item" href="https://wikis.utexas.edu/display/gorislab">Wiki</a></li>
						
        			</ul>
				</div>	
						
				<!-- Page Content -->
      			<div class="off-canvas-content" data-off-canvas-content>
					
					<!-- Foundation Mobile Menu -->
					
					<div class="titlebar show-for-small-only">
						<div class="title-bar left">
							<button class="menu-icon" type="button" data-open="mobile-menu"></button>
							<span class="title-bar-title">MENU</span>
						</div>
					</div>

					<!-- Partials that make up the site -->
		  			<!-- BEGIN NAV BAR DESKTOP -->

<nav class="top-bar nav-desktop ">
	<div class="wrapper">
		<div class="top-bar-left">
			<a href="/"><h3 class="site-logo">Gorislab</h3></a>
		</div>
  		
		<div class="top-bar-right">
        	<menu class="menu horizontal menu-desktop">
				
			
          	<li><a class="nav-item" href="/research">Research</a></li>
					
		<li><a class="nav-item" href="/publications">Publications</a></li>
					
		<li><a class="nav-item" href="/labmembers">Members</a></li>
					
		<li><a class="nav-item" href="/collabs">Collaborators</a></li>
						
          	<li><a class="nav-item" href="/resources">Resources</a></li>
						
          	<li><a class="nav-item" href="https://wikis.utexas.edu/display/gorislab">Wiki</a></li>
			
        	</menu>
  	  	</div>
	</div>
</nav> <!-- END NAV BAR DESKTOP -->
		
					<!-- BEGIN HERO PANEL -->

<section class="hero-panel">
	<div class="wrapper">
		<h1></h1>
		<p></p>
	</div>
</section> <!-- END HERO PANEL -->

						
					
					<section class="main-content">
						<div class="wrapper row">
							<div class="small-12 medium-12 column content-one">
								<h1>Research Projects</h1>
								<p> 

<h4 id="predictive-vision"><em>Predictive Vision</em></h4>

<p>The brain is built to predict. It predicts the consequences of movement in the environment, the actions needed for survival, but also fundamental things such as what we will see in the coming seconds. Visual prediction is difficult because natural input (the stream of images on the retina) evolves according to irregular, jagged temporal trajectories. We introduced the “temporal straightening” hypothesis, positing that sensory systems seek to transform their input such that neural representations follow straighter temporal trajectories. This facilitates prediction: It is easier to predict the progression of a straight line than of an irregular curve. Our hypothesis enjoys some empirical support: We found that the human visual system selectively straightens natural videos. Temporal straightening may thus be a general objective of the visual system adapted to the statistics of the natural environment. We are currently studying the neural basis of temporal straightening by characterizing neural trajectories throughout the visual processing hierarchy.</p>

<p>Hénaff O. J., Goris R. L. T., &amp; Simoncelli E. P. (2019). Perceptual straightening of natural videos. Nature Neuroscience 22, 984–991. <a href="/Henaff, Goris &amp; Simoncelli (2019).pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>

<h4 id="flexible-decision-making"><em>Flexible Decision-making</em></h4>

<p>Organisms perform perceptual tasks across a wide variety of contexts. This necessitates sensory coding strategies that seek to jointly interpret incoming sensory signals and keep track of contextual changes in the environment. Although this is a critical feature of our behavioral repertoire, we have limited insight into the neural computations underlying this flexibility. We develop computational observer models that can solve this challenge optimally and compare it’s features to behavior as well as neural representations of sensory information and task-context. Our previous work has called into question neural signatures traditionally thought to reflect decision strategy in early sensory cortex, while also discovering that stimulus expectations can strongly modulate those same neural responses. We are currently recording from neurons in both sensory and frontal association areas of the brain while animals perform dynamic decision-making tasks to investigate the neural basis of flexible decision-making.</p>

<p>Goris RLT, Ziemba CM, Stine GM, Simoncelli EP, &amp; Movshon JA (2017). Dissociation of choice formation and choice-correlated activity in macaque visual cortex. Journal of Neuroscience 37, 5195-5203. <a href="/Goris, Ziemba et al (2017).pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>

<h4 id="sensory-uncertainty"><em>Sensory Uncertainty</em></h4>

<p>Perceptual systems offer a window on the world in the face of uncertainty. Ideal perceptual systems do not ignore uncertainty, but take it into account. For example, if a sensory cue is ambiguous, prior experience should guide the interpretation of the environment. And if multiple sensory cues are available, they should be combined in proportion to their reliability. When performing perceptual tasks, observers often follow these normative predictions. This implies that neural circuits which process sensory information also survey the uncertainty of this information. How this works is a much debated question. We recently proposed a view of the visual cortex in which average response magnitude encodes stimulus features, while variability in response gain encodes the uncertainty of these features. Our work has revealed that the gain variability of neurons across the visual cortex is indeed associated with uncertainty in the features encoded by those neurons, that this behavior arises from known gain-control mechanisms, and that stimulus uncertainty can be readily decoded by downstream circuits from such a representation.</p>

<p>Hénaff O. J., Boundy-Singer Z., Meding K., Ziemba C. M., &amp; Goris R. L. T. (2020). Representation of visual uncertainty through neural gain variability. Nature Communications 11, 2513. <a href="/H-naff_et_al-2020-Nature_Communications.pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>

<h4 id="cortical-computation"><em>Cortical Computation</em></h4>

<p>The responses of visual neurons have been fruitfully studied for decades using simple artificial stimuli such as sinusoidal gratings and white noise. This tradition has uncovered a set of core-computations — linear filtering, nonlinear transduction, and response suppression – that can be expressed in fairly compact models and replicate responses of the early visual system to simple stimuli. However, for natural stimuli, these models have often failed to explain the full complexity of neural responses, and have been less successful when applied to higher visual areas. We combine the development and elaboration of such functional models with new computational techniques for stimulus selection and synthesis. Our approach will lead to new insights about the neural representation of visual information and its consequences for perception in V1 and beyond.</p>

<p>Goris, R. L. T., Simoncelli, E. P., &amp; Movshon, J. A. (2015). Origin and function of tuning diversity in macaque visual cortex. Neuron, 88(4), 819–831. <a href="/Goris, Simoncelli, Movshon (2015).pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>

<h4 id="neural-variability"><em>Neural Variability</em></h4>

<p>Sensory information is encoded in the activity of populations of sensory neurons: Different stimuli elicit different patterns of activity. Yet, spiking activity is not uniquely determined by external stimuli. Repeated presentations of the same stimulus also elicit different response patterns. To understand how the brain analyzes sensory information and how this process is corrupted by internal noise, we need simple mathematical models that accurately describe this variability. We develop such models and use them to examine how the brain encodes and decodes sensory information. We introduced the “Modulated Poisson model”, which describes spikes as arising from a Poisson process whose input is the product of a deterministic stimulus drive and a stochastic response gain. We found that gain fluctuations account for a large share of cortical response variability, are shared among nearby neurons, have slow temporal dynamics, and are stabilized by visual attention.</p>

<p>Goris, R. L. T., Ziemba, C. M., Movshon, J. A., &amp; Simoncelli, E. P. (2018). Slow gain fluctuations limit benefits of temporal integration in visual cortex. Journal of Vision, 18(8):8, 1–13. <a href="/Goris, Ziemba, Movshon &amp; Simoncelli (2018).pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>

<p>Rabinowitz, N. C., Goris, R. L. T., Cohen, M. R., &amp; Simoncelli, E. P. (2015). Attention stabilizes the shared gain of V4 populations. eLife, e08998. <a href="/Rabinowitz, Goris, Cohen &amp; Simoncelli (2015).pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>

<p>Goris, R. L. T., Movshon, J. A., &amp; Simoncelli, E. P. (2014). Partitioning neuronal variability. Nature Neuroscience, 17, 858–865. <a href="/Goris, Movshon &amp; Simoncelli (2014).pdf"><img src="../img/pdf icon.jpg" alt="pdf download" /></a></p>
 </p>
							</div>
						</div>
					</section>
							
					<!-- BEGIN FOOTER -->
<footer>
<div class="wrapper row small-up-1 medium-up-3">
		
		<div class="column">
			<h4>Contact Info</h4>
			<hr>
			<a><span>Email </span>robbe.goris@utexas.edu</a>
			<a><span>Address </span>CPS, UT Austin, SEA 4.328A, Mailcode A8000, Austin, TX, 78712</a>
		</div>
		
		<div class="column">
			<h4>Links</h4>
			<hr>
			
			
			<a class="nav-item" href="/research">Research</a>
					
			<a class="nav-item" href="/publications">Publications</a>
					
			<a class="nav-item" href="/labmembers">Members</a>
					
			<a class="nav-item" href="/collabs">Collaborators</a>
						
          		<a class="nav-item" href="/resources">Resources</a>
						
          		<a class="nav-item" href="https://wikis.utexas.edu/display/gorislab">Wiki</a>
			
		</div>
		
		<div class="column">
			<h4>Social</h4>
			<hr>
			
			
			<a class="nav-item" href="http://github.com" rel="me">Github</a>
			
			<a class="nav-item" href="http://twitter.com/GorisLab" rel="me">Twitter</a>
			
		</div>

	</div>
</footer> <!-- END FOOTER -->
	

				</div> <!-- End page content menu wrapper -->
		
			</div> <!-- End of global off canvas inner wrapper -->
		</div> <!-- End of global off canvas wrapper -->
		
		
		<!-- JS includes -->
		
		<script src="/js/jquery.js"></script>
		<script src="/js/what-input.js"></script>
		<script src="/js/foundation.js"></script>
		<script src="/js/app.js"></script>
		
	</body>
</html>
  
  
  
  
